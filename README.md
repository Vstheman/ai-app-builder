ğŸ§  AI-Powered RAG Chatbot

A self-updating, document-aware conversational assistant built end-to-end with OpenAI, Python, and smart caching.

ğŸš€ Overview

This project is part of my AI App Builder program, where Iâ€™m mastering end-to-end development of LLM-powered apps.

Itâ€™s a Retrieval-Augmented Generation (RAG) Chatbot that can:

ğŸ’¬ Chat conversationally like ChatGPT

ğŸ“š Answer questions based on your own documents (TXT, Markdown, PDF)

ğŸ” Auto-detect & re-embed changed files (no manual refresh)

ğŸ’¾ Maintain conversation memory between turns

ğŸ§  Auto-summarize long chats to save tokens

ğŸ›¡ï¸ Filter unsafe prompts with moderation

ğŸ“Š Log all queries, answers, and usage metrics

ğŸ§© Architecture
data/
 â”œâ”€â”€ docs/            # Your knowledge base (.txt, .md, .pdf)
 â”œâ”€â”€ cache/           # Per-file embedding caches
 â”œâ”€â”€ index.jsonl      # Global chunk metadata
 â””â”€â”€ vectors.npy      # Global embedding matrix
api/
 â”œâ”€â”€ retriever.py     # Semantic search via cosine similarity
 â”œâ”€â”€ rag_cli.py       # One-shot RAG Q&A
 â”œâ”€â”€ chat_cli.py      # Basic multi-turn chat
 â””â”€â”€ rag_chatbot.py   # Full RAG Chatbot (auto-refresh + memory)
logs/
 â”œâ”€â”€ rag_chat_history.json
 â””â”€â”€ dayXX-*.jsonl

âš™ï¸ Features
Feature	Description
ğŸ§© RAG (Retrieval Augmented Generation)	Retrieves most relevant document chunks before every answer
ğŸ” Smart Cache	Reuses embeddings for unchanged files, re-embeds only modified ones
ğŸ“„ PDF Support	Extracts text automatically using pypdf
ğŸ’¬ Conversational Memory	Maintains multi-turn chat context with summarization
ğŸ§± Local Vector Index	Built with NumPy â€” no external vector DB required
ğŸ›¡ï¸ Moderation & Logging	Filters unsafe content and records all chat data
âš¡ Fast Startup	Scans & validates docs in seconds, even for large folders
ğŸ› ï¸ Setup
1ï¸âƒ£ Clone the repo
git clone https://github.com/<your-username>/ai-app-builder.git
cd ai-app-builder

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt


(Ensure you have openai>=1.40.0 and pypdf>=4.0.0.)

3ï¸âƒ£ Add your documents

Place .txt, .md, or .pdf files in:

data/docs/

4ï¸âƒ£ Add your OpenAI API key

Create an .env file or set the environment variable:

export OPENAI_API_KEY="sk-..."


(On Windows PowerShell:)

$env:OPENAI_API_KEY="sk-..."

5ï¸âƒ£ Run the chatbot
python api/rag_chatbot.py


Youâ€™ll see:

â€¢ Reused cache (5 chunks) â†’ data/docs/faq.txt
â€¢ Embedded 3 chunks â†’ data/docs/policy.pdf
âœ… Embedding index up-to-date (8 vectors)
ğŸ§  RAG Chatbot (auto-updates embeddings; PDF-ready)

ğŸ’¬ Example Session
You: What is the new lunch policy?
AI: Employees now get one hour for lunch as per the updated policy. [Source: policy.pdf]

You: What about weekends?
AI: The lunch policy applies only on weekdays. [Source: policy.pdf]

ğŸ§  How It Works (Under the Hood)
Step	Description
1ï¸âƒ£ Ingestion	On startup, reads all files â†’ hashes â†’ detects changes
2ï¸âƒ£ Embedding	Generates semantic vectors using text-embedding-3-small
3ï¸âƒ£ Indexing	Stores vectors in vectors.npy and metadata in index.jsonl
4ï¸âƒ£ Retrieval	At each query, finds top-k similar chunks via cosine similarity
5ï¸âƒ£ Response	Builds augmented prompt (context + question) â†’ GPT â†’ answer
6ï¸âƒ£ Memory	Saves full chat and auto-summarizes when too long
ğŸ§¾ Logs

Every conversation turn is logged in:

logs/day11-ragchat.jsonl


Example log entry:

{
  "ts": "2025-10-05T10:21:43Z",
  "user": "What is the refund policy?",
  "assistant": "Refunds are processed within 7 business days.",
  "sources": ["data/docs/policy.pdf"],
  "usage": {"prompt_tokens": 520, "completion_tokens": 65}
}

âœ¨ Author
Varun Shetty
Building AI-powered apps that combine data, design, and intelligence.